{"cells":[{"cell_type":"code","execution_count":25,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-07-26T22:18:55.591368Z","iopub.status.busy":"2022-07-26T22:18:55.590843Z","iopub.status.idle":"2022-07-26T22:19:06.368515Z","shell.execute_reply":"2022-07-26T22:19:06.367407Z","shell.execute_reply.started":"2022-07-26T22:18:55.591326Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['figure.figsize'] = (10, 5)\n","np.random.seed(1234)\n","\n","!pip install git+https://github.com/brendanartley/Regressio --quiet"]},{"cell_type":"markdown","metadata":{},"source":["### Cubic Spline Article\n","\n","In this article I will go through cubic splines, and show why they are a more robust solution than linear/polynommial regression. First I will walk through the mathematics behind cub splines, then I will explain Runge's phenomonon, and finally I will introduce [Regressio](https://github.com/brendanartley/Regressio). Regressio is a python library for univariate regression, interpolation and smoothing."]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","\n","\n","Firstly, cubic spline is a piecewise interpolation model that fits a cubic polynomial to each \"piece\" of the function. At the point where 2 polynomials meet, the 1st and 2nd derivatives are equal. This makes for a smooth fitting line.\n","\n","For example, in the image above we can see how a cubic polynomial may be split. In this image there are 3 pieces, and the two central blue points are where polynomials intercect. We can see that the function is smooth around this point, and that the entire function is continous. Lets look at the mathematics behind fitting this regression line."]},{"cell_type":"markdown","metadata":{},"source":["## Mathematics\n","\n","Lets say we have three data points (2,3), (3,2), (4,4). When calculating the cubic spline betweens points, we need n-1 piecewise functions that regression models to the third degree.\n","\n","Since we have 3 data points, we will need 2 piecewise functions. We will denote these as $f_1(x)$ and $f_2(x)$.\n","\n","$$\n","f(x) = \n","    \\begin{cases}\n","        f_1(x) = a_1x_1^3 + b_1x_1^2 + c_1x_1 + d_1, \\quad{}\\text{for 2 <= f(x) <= 3} \\\\\n","        f_2(x) = a_1x_2^3 + b_1x_2^2 + c_1x_2 + d_1, \\quad{}\\text{for 3 <= f(x) <= 4}\n","    \\end{cases}\n","$$\n","\n","In each equation above we have 4 unknown variables (a, b, c, d). We will need to set up a system of equations to calculate for each equation, so therefore we have a total of 8 unknowns.\n","\n","First, we know that for the 1st and 2nd points, these must fall on the first function.\n","\n","$$ f_1(x) = a_1x_1^3 + b_1x_1^2 + c_1x_1 + d_1 = y_1$$\n","\n","$$ f_1(x) = a_1x_2^3 + b_1x_2^2 + c_1x_2 + d_1 = y_2$$\n","\n","Next, we know that the second and third points must fall on the second function.\n","\n","$$ f_2(x) = a_2x_2^3 + b_2x_2^2 + c_2x_2 + d_2 = y_2$$\n","\n","$$ f_2(x) = a_2x_3^3 + b_2x_3^2 + c_2x_3 + d_2 = y_3$$\n","\n","We also know that the 1st derivatives of two functions must be equal when they intercept. This is when we are at the second data point.\n","\n","$$ f_1'(x) = f_2'(x)$$\n","\n","$$ 3a_1x_2^2 + 2b_1x_2 + c_1 = 3a_2x_2^2 + 2b_2x_1 + c_2$$\n","\n","$$ 3a_1x_2^2 + 2b_1x_2 + c_1 - 3a_2x_2^2 - 2b_2x_1 - c_2 = 0$$\n","\n","Then, we also know that the 2nd derviatives of the intersecting splines must be equal so we can form the equation.\n","\n","$$ f_1''(x) = f_2''(x)$$\n","\n","$$ 6a_1x_2 + 2b_1 = 6a_2x_2^2 + 2b_2$$\n","\n","$$ 6a_1x_2 + 2b_1 - 6a_2x_2^2 - 2b_2 = 0$$\n","\n","Finally, we want the 2nd derivatives at each endpoint to be 0. This makes the spline 'natural'.\n","\n","$$ 6a_1x_1 + 2b_1 = 0$$\n","\n","$$ 6a_2x_3 + 2b_2 = 0$$\n","\n","The resulting 8 equations are as follows.\n","\n","$$ a_1x_1^3 + b_1x_1^2 + c_1x_1 + d_1 = y_1$$\n","\n","$$ a_1x_2^3 + b_1x_2^2 + c_1x_2 + d_1 = y_2$$\n","\n","$$ a_2x_2^3 + b_2x_2^2 + c_2x_2 + d_2 = y_2$$\n","\n","$$ a_2x_3^3 + b_2x_3^2 + c_2x_3 + d_2 = y_3$$\n","\n","$$ 3a_1x_2^2 + 2b_1x_2 + c_1 - 3a_2x_2^2 - 2b_2x_1 - c_2 = 0$$\n","\n","$$ 6a_1x_2 + 2b_1 - 6a_2x_2^2 - 2b_2 = 0$$\n","\n","$$ 6a_1x_1 + 2b_1 = 0$$\n","\n","$$ 6a_2x_3 + 2b_2 = 0$$\n","\n","We can then plug in the three data points (2,3), (3,2), (4,4).\n","\n","$$ 8a_1 + 4b_1 + 2c_1 + d_1 = 3$$\n","\n","$$ 27a_1 + 9b_1 + 3c_1 + d_1 = 2$$\n","\n","$$ 27a_2 + 9b_2 + 3c_2 + d_2 = 2$$\n","\n","$$ 64a_2 + 16b_2 + 4c_2 + d_2 = 4$$\n","\n","$$ 27a_1 + 6b_1 + c_1 - 27a_2 - 6b_2 - c_2 = 0$$\n","\n","$$ 18a_1 + 2b_1 - 18a_2 - 2b_2 = 0$$\n","\n","$$ 12a_1 + 2b_1 = 0$$\n","\n","$$ 24a_2 + 2b_2 = 0$$\n","\n","The equations above can then be represented in matrix form and solved using linear algebra. The equations are represented in a matrix of size 4 x (n - 1). In this example the matrix will be 8x8.\n","\n","$$ A(x)\\cdot{\\overrightarrow{c(x)}} = \\overrightarrow{b(x)} $$\n","\n","$$\n","\\begin{bmatrix} \n","8 & 4 & 2 & 1 & 0 & 0 & 0 & 0 \\\\\n","27 & 9 & 3 & 1 & 0 & 0 & 0 & 0 \\\\\n","0 & 0 & 0 & 0 & 27 & 9 & 3 & 1 \\\\\n","0 & 0 & 0 & 0 & 64 & 16 & 4 & 1 \\\\\n","27 & 6 & 1 & 0 & -27 & -6 & -1 & 0 \\\\\n","18 & 2 & 0 & 0 & -18 & -2 & 0 & 0 \\\\\n","12 & 2 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n","0 & 0 & 0 & 0 & 24 & 2 & 0 & 0\n","\\end{bmatrix} \\cdot\n","\\begin{bmatrix} \n","a_1 \\\\ b_1 \\\\ c_1 \\\\ d_1 \\\\ a_2 \\\\ b_2 \\\\ b_3 \\\\ b_4\n","\\end{bmatrix}\n","= \n","\\begin{bmatrix} \n","3 \\\\ 2 \\\\ 2 \\\\ 4 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\n","\\end{bmatrix}\n","$$\n","\n","$$ \\overrightarrow{c(x)} = A(x)^{-1}\\cdot{b(x)} $$\n","\n","$$ \n","\\overrightarrow{c(x)} =\n","\\begin{bmatrix}\n","0.75 \\\\ -4.5 \\\\ 7.25 \\\\ 0.5 \\\\ -0.75 \\\\ 9 \\\\ -33.25 \\\\ 41\n","\\end{bmatrix}\n","$$ \n","\n","We can now plug these values back into our two equations and we have the piecewise function!\n","\n","$$\n","f(x) = \n","    \\begin{cases}\n","        f_1(x) = 0.75x^3 -4.5x^2 + 7.25x + 0.5, \\quad{}\\text{for 2 <= f(x) <= 3} \\\\\n","        f_2(x) = -0.75x^3 + 9x^2 - 33.25x + 41, \\quad{}\\text{for 3 <= f(x) <= 4}\n","    \\end{cases}\n","$$"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T22:19:06.370896Z","iopub.status.busy":"2022-07-26T22:19:06.370508Z","iopub.status.idle":"2022-07-26T22:19:06.636949Z","shell.execute_reply":"2022-07-26T22:19:06.636116Z","shell.execute_reply.started":"2022-07-26T22:19:06.370848Z"},"trusted":true},"outputs":[],"source":["# Input Data\n","raw_x, raw_y = np.asarray([2,3,4]), np.asarray([3,2,4])\n","\n","# Calculating Weights\n","b = np.array([3,2,2,4,0,0,0,0], dtype=np.float64)\n","A = np.array([[8,4,2,1,0,0,0,0],\n","              [27,9,3,1,0,0,0,0], \n","              [0,0,0,0,27,9,3,1],\n","              [0,0,0,0,64,16,4,1],\n","              [27,6,1,0,-27,-6,-1,0],\n","              [18,2,0,0,-18,-2,0,0],\n","              [12,2,0,0,0,0,0,0],\n","              [0,0,0,0,24,2,0,0]], dtype=np.float64)\n","\n","lines = np.dot(np.linalg.inv(A), b).reshape(-1, 4)\n","\n","# Calculates x**0 + x**1 + x**2 + x**3\n","def plot(values, coeffs):\n","    # Coeffs are assumed to be in order 0, 1, ..., n-1\n","    expanded = np.hstack([coeffs[i] * (values ** i) for i in range(0, len(coeffs))])\n","    return np.sum(expanded, axis=1)\n","\n","xs = np.linspace(raw_x.min(), raw_x.max(), 100)\n","y1s = plot(xs[xs<=3].reshape(-1,1), lines[0][::-1])\n","y2s = plot(xs[xs>3].reshape(-1,1), lines[1][::-1])\n","ys = np.concatenate([y1s, y2s])\n","\n","plt.plot(xs, ys)\n","plt.scatter(raw_x, raw_y)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Regressio Library\n","\n","Now what happens when we have 200 points, and we want to fit 10 piecewise cubic polynomials?\n","\n","This could do it by hand, but it is much easier to use an existing python library. We will use a package called [Regressio](https://github.com/brendanartley/Regressio) to do just that. In the following cell we are generating a random sample of 200 data points."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T22:19:06.639023Z","iopub.status.busy":"2022-07-26T22:19:06.638217Z","iopub.status.idle":"2022-07-26T22:19:17.250182Z","shell.execute_reply":"2022-07-26T22:19:17.248769Z","shell.execute_reply.started":"2022-07-26T22:19:06.638957Z"},"trusted":true},"outputs":[],"source":["from regressio.datagen import generate_random_walk\n","\n","x, y = generate_random_walk(200, plot=True)"]},{"cell_type":"markdown","metadata":{},"source":["Then, we can simply import a cubic spline model and fit the model to the data."]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-07-26T22:19:17.254067Z","iopub.status.busy":"2022-07-26T22:19:17.253292Z","iopub.status.idle":"2022-07-26T22:19:17.479257Z","shell.execute_reply":"2022-07-26T22:19:17.478083Z","shell.execute_reply.started":"2022-07-26T22:19:17.254013Z"},"trusted":true},"outputs":[],"source":["from regressio.models import cubic_spline\n","\n","model = cubic_spline(pieces=10)\n","model.fit(x, y, plot=True)"]},{"cell_type":"markdown","metadata":{},"source":["This is pretty amazing model as we can fit highly variable relationships using mutliple low degree polynomials.\n","\n","## Runge's Phenomenon\n","\n","Fitting spline models was exactly what Carl David Tolm√© Runge was doing in 1901, and he found that polynomial interpolation methods such as cubic spline outperformed linear regression models with high degrees. This is due to large osciallations at the edges of intervals in linear regression models. This is visualized nicely in this image by John D. Cook below.\n","\n","\n","This is significant because if we are given a data point that falls just outside of the boundaries of the training data, then small changes in x will result in very different predictions.\n","\n","## Final Thoughts\n","\n","Cubic spline is a more robust alternative to high degree linear regression models. I am suprised this is not taught directly after linear regression, as it addresses some of the model flaws. \n","\n","If you want to work through more examples of cubic spline, I encourage you to explore the [Regressio module](https://github.com/brendanartley/Regressio) and the source code. As the author of this package, I made the code base very readable for those trying to understand the models. \n","\n","And if you would like the notebook code for this article, you can find that [here](https://github.com/brendanartley/Medium-Article-Code).\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
